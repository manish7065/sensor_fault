[2023-01-09 11:07:15,461]^;INFO^;27^;training_pipeline.py^;start_data_ingestion()^;starting data ingestion. 
[2023-01-09 11:07:15,502]^;INFO^;83^;data_ingestion.py^;initiate_data_ingestion()^;<<<<<<<<<<<<<<<<<<<< Initiating the Data Ingestion. >>>>>>>>>>>>>>>>>>>>
[2023-01-09 11:07:15,502]^;INFO^;26^;data_ingestion.py^;export_data_into_feature_store()^;Exporting data from mongoDB to feature_store. 
[2023-01-09 11:07:26,024]^;INFO^;58^;data_ingestion.py^;split_data_as_train_test()^;performed train test split on DataFrame
[2023-01-09 11:07:26,024]^;INFO^;62^;data_ingestion.py^;split_data_as_train_test()^;Creating the data ingestion directory to store the splited data at:artifact/01_09_2023_11_06_36/data_ingestion/ingested
[2023-01-09 11:07:26,024]^;INFO^;66^;data_ingestion.py^;split_data_as_train_test()^;Exporting train test data to the directory 
[2023-01-09 11:07:28,083]^;INFO^;76^;data_ingestion.py^;split_data_as_train_test()^;Exported train and test file path.
[2023-01-09 11:07:28,192]^;INFO^;92^;data_ingestion.py^;initiate_data_ingestion()^;Data ingestion Artifact sucessfully completed: DataIngestionArtifact(trained_file_path='artifact/01_09_2023_11_06_36/data_ingestion/ingested/train.csv', test_file_path='artifact/01_09_2023_11_06_36/data_ingestion/ingested/test.csv')
[2023-01-09 11:07:28,192]^;INFO^;93^;data_ingestion.py^;initiate_data_ingestion()^; <<<<<<<<<<<<<<<<<<<< Data ingestion completed sucessfully. >>>>>>>>>>>>>>>>>>>> 

[2023-01-09 11:07:28,481]^;INFO^;32^;training_pipeline.py^;start_data_ingestion()^;data insgestion completed at artifact: DataIngestionArtifact(trained_file_path='artifact/01_09_2023_11_06_36/data_ingestion/ingested/train.csv', test_file_path='artifact/01_09_2023_11_06_36/data_ingestion/ingested/test.csv') 
[2023-01-09 11:07:28,482]^;INFO^;43^;training_pipeline.py^;start_data_validation()^;Data valiodation starts
[2023-01-09 11:07:28,521]^;INFO^;107^;data_validation.py^;initiate_data_validation()^;<<<<<<<<<<<<<<<<<<<< Initiating Data Validation >>>>>>>>>>>>>>>>>>>>
[2023-01-09 11:07:28,991]^;INFO^;96^;data_validation.py^;validate_no_of_columns()^;Required number of columns: 164
[2023-01-09 11:07:28,991]^;INFO^;97^;data_validation.py^;validate_no_of_columns()^;Data frame has columns: 164
[2023-01-09 11:07:28,991]^;INFO^;96^;data_validation.py^;validate_no_of_columns()^;Required number of columns: 164
[2023-01-09 11:07:28,991]^;INFO^;97^;data_validation.py^;validate_no_of_columns()^;Data frame has columns: 164
[2023-01-09 11:07:28,992]^;INFO^;51^;data_validation.py^;is_numerical_column_exist()^;Missing numerical columns: [[]]
[2023-01-09 11:07:28,992]^;INFO^;51^;data_validation.py^;is_numerical_column_exist()^;Missing numerical columns: [[]]
[2023-01-09 11:07:30,060]^;INFO^;150^;data_validation.py^;initiate_data_validation()^;Data Validation Artifact: DataValidationArtifact(validation_status=False, valid_train_file_path='artifact/01_09_2023_11_06_36/data_ingestion/ingested/train.csv', valid_test_file_path='artifact/01_09_2023_11_06_36/data_ingestion/ingested/test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='artifact/01_09_2023_11_06_36/data_validation/drift_report/report.yaml') 
[2023-01-09 11:07:30,060]^;INFO^;151^;data_validation.py^;initiate_data_validation()^;<<<<<<<<<<<<<<<<<<<< Data Validation Completed Sucessfully. >>>>>>>>>>>>>>>>>>>> 

[2023-01-09 11:07:30,061]^;INFO^;58^;training_pipeline.py^;start_data_transformation()^;Start Data Transformation
[2023-01-09 11:07:30,061]^;INFO^;57^;data_transformation.py^;initiate_data_transformation()^;<<<<<<<<<<<<<<<<<<<< Initiating data transformation. >>>>>>>>>>>>>>>>>>>>
[2023-01-09 11:07:37,379]^;INFO^;53^;main_utils.py^;save_object()^;Entered the save_object method of main utils class
[2023-01-09 11:07:37,383]^;INFO^;57^;main_utils.py^;save_object()^;Exited the save_object method of MainUtils class
[2023-01-09 11:07:37,383]^;INFO^;104^;data_transformation.py^;initiate_data_transformation()^;Data transformantion articat: DataTransformationArtifact(transformed_object_file_path='artifact/01_09_2023_11_06_36/data_transformation/transformed_object/preprocessing.pkl', transformed_train_file_path='artifact/01_09_2023_11_06_36/data_transformation/transformed/train.npy', transformed_test_file_path='artifact/01_09_2023_11_06_36/data_transformation/transformed/test.npy')
[2023-01-09 11:07:37,383]^;INFO^;105^;data_transformation.py^;initiate_data_transformation()^;<<<<<<<<<<<<<<<<<<<< Data Transformation Completed Sucessfully. >>>>>>>>>>>>>>>>>>>> 

[2023-01-09 11:07:45,626]^;INFO^;53^;main_utils.py^;save_object()^;Entered the save_object method of main utils class
[2023-01-09 11:07:45,633]^;INFO^;57^;main_utils.py^;save_object()^;Exited the save_object method of MainUtils class
[2023-01-09 11:07:45,633]^;INFO^;82^;model_trainer.py^;initiate_model_trainer()^;Model Trainer Artifact: ModelTrainerArtifact(trained_model_file_path='artifact/01_09_2023_11_06_36/model_trainer/trained_model/model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=1.0, precision_score=1.0, recall_score=1.0), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9839782345828294, precision_score=0.9943485565908049, recall_score=0.9738219895287958))
[2023-01-09 11:07:46,553]^;INFO^;88^;model_evaluatiom.py^;initiate_model_evaluation()^;Model Evaluation Artifact: ModelEvaluationArtifact(is_model_accepted=False, improved_accuracy=-0.0052721326659253, best_model_path=None, trianed_model_path=None, train_model_metric_artifact='artifact/01_09_2023_11_06_36/model_trainer/trained_model/model.pkl', test_model_metric_artifact=ClassificationMetricArtifact(f1_score=0.981404958677686, precision_score=0.974025974025974, recall_score=0.9888965995836225))
[2023-01-09 11:07:46,554]^;INFO^;29^;exception.py^;__init__()^;
        Error occured in script: 
        [ /config/workspace/sensor/pipeline/training_pipeline.py ] at 
        try block line number: [132] and exception block line number: [142] 
        error message: [Trained model is not better than best model]
        
